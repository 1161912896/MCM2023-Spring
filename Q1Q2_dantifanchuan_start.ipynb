{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 is about monohulled sailboats from 2023_MCM_Problem_Y_Boats.xlsx, the provied excl file\n",
    "data1=pd.read_excel('2023_MCM_Problem_Y_Boats.xlsx',sheet_name='Monohulled Sailboats ')\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### sailboat data from ：sailboatdata.com\n",
    "### We select LWL (ft)\tBeam (ft)\tDraft (ft)\tDisplacement (lbs)\tSail Area (sq ft) from the webset(sailboatdata.com) and saved it as sheet Monohulled Sailboats_supply in 2023_MCM_Problem_Y_Boats.xlsx\n",
    "\n",
    "# concat column A and coulmn B to \"单体帆船型号\" as colum A, and drop the original column A and B\n",
    "# get data from sailboatdata.com as supplymentary data\n",
    "# read in the new excle file to data2\n",
    "data2=pd.read_excel('2023_MCM_Problem_Y_Boats.xlsx',sheet_name='Monohulled Sailboats_supply1')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### economy data from :Word Bank etc.\n",
    "### We select Average cargo throughput (tons),GDP (USD billion), GDP per capita (USD),Average ratio of total logistics costs to GDP(USD) from the websets(WordBank etc.) and saved it as sheet Monohulled Sailboats_supply in 2023_MCM_Problem_Y_Boats.xlsx\n",
    "### the same merge method as above\n",
    "data3=pd.read_excel('2023_MCM_Problem_Y_Boats.xlsx',sheet_name='Monohulled Sailboats_supply2')\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in ['平均货物吞吐量（吨）', 'GDP（亿美元）', '人均GDP（美元）', '物流总成本占GDP的平均比例']:\n",
    "    # check the unique value of each column\n",
    "    print(data3[i].unique())\n",
    "    # replace '-' with NaN\n",
    "    data3[i]=data3[i].apply(lambda x:np.NaN if x=='-' else x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getx(x):\n",
    "    # get the make and variant of the boat\n",
    "    return str(x['Make'])+' '+str(x['Variant'])\n",
    "# add a new column 'Make Variant' to data1\n",
    "data1['Make Variant']=data1.apply(lambda x:getx(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of data1,data2,data3\n",
    "print(data1.shape,data2.shape,data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the unique value of 'Make Variant' and '单体帆船型号'\n",
    "print(data1['Make Variant'].nunique())\n",
    "print(data2['单体帆船型号'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the duplicate rows in data2\n",
    "data2=data2.drop_duplicates(keep='first',subset='单体帆船型号')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply() to get the unique value of '单体帆船型号' and 'Make Variant'\n",
    "# replace the space in the column '单体帆船型号' and 'Make Variant' with ''\n",
    "\n",
    "data2['单体帆船型号']=data2['单体帆船型号'].apply(lambda x:x.replace(' ',''))\n",
    "data1['Make Variant']=data1['Make Variant'].apply(lambda x:x.replace(' ',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data['Make Variant'])\n",
    "# datal = data.copy()\n",
    "# datal['MakeVariant'] = datal.apply(lambda x: str(x[0]) + str(x[1]), axis=1)\n",
    "#  datal=datal[['Length \\n(ft)', \n",
    "#         'Listing Price (USD)', 'Year', 'Make Variant',\n",
    "#        'LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "#        'Sail Area (sq ft)', 'Average cargo throughput (tons)',\n",
    "#        'GDP (USD billion)', 'GDP per capita (USD)',\n",
    "#        'Average ratio of total logistics costs to GDP', 'MakeVariant']].copy()\n",
    "# datal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data1 and data2 by 'Make Variant' and '单体帆船型号'\n",
    "data=pd.merge(data1,data2,how='left',left_on='Make Variant',right_on='单体帆船型号')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(data.apply)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the unique value of '城市/地区'\n",
    "print(data3['城市/地区'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data3['城市/地区'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define a function to replace the space in the column '城市/地区' with ''\n",
    "def lowre(i):\n",
    "    try:\n",
    "        return i.lower().replace(' ','')\n",
    "    except:\n",
    "        return i\n",
    "# apply the function to the column '城市/地区'\n",
    "data3['城市/地区']=data3['城市/地区'].apply(lambda j:lowre(j))\n",
    "# merge data and data3 by 'Country/Region/State ' and '城市/地区'\n",
    "data['Country/Region/State ']=data1['Country/Region/State '].apply(lambda j:lowre(j))\n",
    "data=pd.merge(data,data3,how='left',left_on='Country/Region/State ',right_on='城市/地区')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the columns of data\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns of data\n",
    "data.columns=['Make', 'Variant', 'Length \\n(ft)', 'Geographic Region',\n",
    "       'Country/Region/State ', 'Listing Price (USD)', 'Year', 'Make Variant',\n",
    "       'Make Variant2', 'LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "       'Sail Area (sq ft)', 'City/Region', 'Average cargo throughput (tons)', 'GDP (USD billion)', 'GDP per capita (USD)',\n",
    "       'Average ratio of total logistics costs to GDP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns of data\n",
    "data=data[['Make', 'Variant', 'Length \\n(ft)', 'Geographic Region',\n",
    "       'Country/Region/State ', 'Listing Price (USD)', 'Year', 'Make Variant',\n",
    "        'LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "       'Sail Area (sq ft)', 'Average cargo throughput (tons)', 'GDP (USD billion)', 'GDP per capita (USD)',\n",
    "       'Average ratio of total logistics costs to GDP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data as Monohulled Sailboats.xlsx index=None means not to save the index\n",
    "data.to_excel('./Q1/Monohulled Sailboats/Monohulled Sailboats.xlsx',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "#sorting and counting the frequency of values in the 'Make' column of a DataFrame called data.\n",
    "df1=pd.DataFrame(sorted(Counter(data['Make']).items(), key=lambda x: x[1], reverse=False),columns=['Make','Make num'])\n",
    "\n",
    "# save the df1 as df1.xlsx index=None means not to save the index\n",
    "df1.to_excel('./Q1/Monohulled Sailboats/df1.xlsx',index=None)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "n=12\n",
    "# Chineses font\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "\n",
    "# minus sign\n",
    "plt.rcParams['axes.unicode_minus']=False \n",
    "\n",
    "# show the plot in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# define the number of the bar\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the size of the figure\n",
    "plt.figure(figsize=(12, 12), dpi=100)\n",
    "df_sorted = df1.sort_values(by='Make num', ascending=False)\n",
    "\n",
    "# create a seaborn barplot\n",
    "sns.barplot(x=\"Make num\", y=\"Make\", data=df_sorted.head(n), color='#2A9D8E')\n",
    "\n",
    "# set the title of the plot\n",
    "plt.title(\"The Top 12 Make With The Highest Frequency\", fontsize=20)\n",
    "plt.ylabel('Name of Make', fontsize=13)\n",
    "plt.xlabel(\"Records of each Make\", fontsize=13)\n",
    "\n",
    "# add annotations to the bars\n",
    "for i, v in enumerate(df_sorted['Make num'].head(n)):\n",
    "    plt.text(v + 0.2, i + .15, str(v), color='black', fontweight='bold')\n",
    "\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)  # add gridlines on the x-axis with dashed lines and transparency\n",
    "# adjust the layout\n",
    "plt.tight_layout()\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# save the plot and show it\n",
    "plt.savefig('./Q1/Monohulled Sailboats/dan-The Top 12 Make With The Highest Frequency.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting and counting the frequency of values in the 'Make Variant' column of a DataFrame called data.\n",
    "df2=pd.DataFrame(sorted(Counter(data['Make Variant']).items(), key=lambda i: i[1], reverse=False),columns=['Make Variant','Make Variant num'])\n",
    "# save the df2 as df2.xlsx index=None means not to save the index\n",
    "df2.to_excel('./Q1/Monohulled Sailboats/df2.xlsx',index=None)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 12  # number of bars to display\n",
    "\n",
    "plt.figure(figsize=(12, 9),dpi=100)  # set the size of the figure\n",
    "plt.barh(df2['Make Variant'].tail(n), df2['Make Variant num'].tail(n), align='center', color='#2A9D8E', alpha=1)\n",
    "\n",
    "plt.title(\"The Top 12 Make Variants With The Highest Frequency\", fontsize=22, fontweight='bold')  # add title with bold font\n",
    "plt.xlabel(\"Number of Make Variants\", fontsize=16)  # increase font size of x-axis label\n",
    "plt.ylabel('Name of Make Variants', fontsize=16)  # increase font size of y-axis label\n",
    "plt.xticks(fontsize=12)  # increase font size of tick labels on x-axis\n",
    "plt.yticks(fontsize=12)  # increase font size of tick labels on y-axis\n",
    "\n",
    "# add annotations to the bars\n",
    "for i, v in enumerate(df2['Make Variant num'].tail(n)):\n",
    "    print(i,v)\n",
    "    plt.text(v + 0.2, i + .15, str(v), color='black', fontweight='bold')\n",
    "    # plt.text(v + 0.2, i + .15, v, color='black', fontweight='bold')\n",
    "\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)  # add gridlines on the x-axis with dashed lines and transparency\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()  # automatically adjust subplot parameters to provide padding between plots\n",
    "\n",
    "plt.savefig('./Q1/Monohulled Sailboats/dan-Make Variant num.jpg', dpi=300)  # save figure with higher resolution\n",
    "plt.show()  # display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colum=data[['Length \\n(ft)',  'Listing Price (USD)', 'Year',\n",
    "       'LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "       'Sail Area (sq ft)', 'Average cargo throughput (tons)',\n",
    "       'GDP (USD billion)', 'GDP per capita (USD)',\n",
    "       'Average ratio of total logistics costs to GDP']].copy()\n",
    "colum.to_csv('./Q1/Monohulled Sailboats/colum.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(70, 19))\n",
    "idx=1\n",
    "for argue in colum:\n",
    "    data_list = list(data[argue])\n",
    "    data_list = [x for x in data_list if str(x) != 'nan']\n",
    "    plt.subplot(2,6,idx)\n",
    "    plt.boxplot(\n",
    "        # data to plot\n",
    "        data_list,\n",
    "        # fill with colors\n",
    "        patch_artist=True,\n",
    "        # don't show line around box\n",
    "        showmeans=True,\n",
    "        # fill with colors\n",
    "        boxprops={'color': '#264653', 'facecolor': '#2A9D8E'},\n",
    "        # change color and linewidth of the whiskers\n",
    "        flierprops={'marker': 'o', 'markerfacecolor': '#e66f51', 'color': 'black'},\n",
    "        # change color and linewidth of the caps\n",
    "        meanprops={'marker': '*', 'markerfacecolor': '#E9C46B'},\n",
    "        # change color and linewidth of the medians\n",
    "        medianprops={'linestyle': '--', 'color': '#264653'})\n",
    "    \n",
    "    # set the title of the plot\n",
    "    if argue == 'Year':\n",
    "        label0 = 'Year'\n",
    "        label1 = 'AD'\n",
    "    elif argue == 'Average ratio of total logistics costs to GDP':\n",
    "        label0 = 'Average ratio of total logistics costs to GDP'\n",
    "        label1 = 'ratio'\n",
    "    else:\n",
    "        if argue=='Length \\n(ft)':\n",
    "            argue='Length (ft)'\n",
    "        label0 = argue.split('(')[0]\n",
    "        label1 = argue.split('(')[1].split(')')[0]\n",
    "\n",
    "    plt.title(str(argue), fontsize=40)\n",
    "    plt.xlabel(label0, fontsize=30)\n",
    "    plt.ylabel(label1, fontsize=30)\n",
    "    idx+=1\n",
    "    # plt.savefig('./Q1/Monohulled Sailboats/dan-xiang-{}.jpg'.format(argue), dpi=300)\n",
    "    # print('./Q1/Monohulled Sailboats/{}.jpg'.format(argue))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for argue in colum:\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # print(label0, label1)\n",
    "    # print(data[argue])\n",
    "    plt.figure(figsize=(8, 5), dpi=100)\n",
    "    # set the size of the figure\n",
    "\n",
    "    data_list = list(data[argue])\n",
    "    data_list = [x for x in data_list if str(x) != 'nan']\n",
    "    plt.boxplot(\n",
    "        # data to plot\n",
    "        data_list,\n",
    "        # fill with colors\n",
    "        patch_artist=True,\n",
    "        # don't show line around box\n",
    "        showmeans=True,\n",
    "        # fill with colors\n",
    "        boxprops={'color': '#264653', 'facecolor': '#2A9D8E'},\n",
    "        # change color and linewidth of the whiskers\n",
    "        flierprops={'marker': 'o', 'markerfacecolor': '#e66f51', 'color': 'black'},\n",
    "        # change color and linewidth of the caps\n",
    "        meanprops={'marker': '*', 'markerfacecolor': '#E9C46B'},\n",
    "        # change color and linewidth of the medians\n",
    "        medianprops={'linestyle': '--', 'color': '#264653'})\n",
    "    \n",
    "    # set the title of the plot\n",
    "    if argue == 'Year':\n",
    "        label0 = 'Year'\n",
    "        label1 = 'AD'\n",
    "    elif argue == 'Average ratio of total logistics costs to GDP':\n",
    "        label0 = 'Average ratio of total logistics costs to GDP'\n",
    "        label1 = 'ratio'\n",
    "    else:\n",
    "        if argue=='Length \\n(ft)':\n",
    "            argue='Length (ft)'\n",
    "        label0 = argue.split('(')[0]\n",
    "        label1 = argue.split('(')[1].split(')')[0]\n",
    "\n",
    "    plt.title(str(argue), fontsize=20)\n",
    "    plt.xlabel(label0, fontsize=13)\n",
    "    plt.ylabel(label1, fontsize=13)\n",
    "    plt.savefig('./Q1/Monohulled Sailboats/dan-xiang-{}.jpg'.format(argue), dpi=300)\n",
    "    print('./Q1/Monohulled Sailboats/{}.jpg'.format(argue))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting and counting the frequency of values in the 'Geographic Region' column of a DataFrame called data.\n",
    "df2 = pd.DataFrame(sorted(Counter(data['Geographic Region']).items(), key=lambda x: x[1], reverse=False), columns=['Geographic Region', 'Geographic Region num'])\n",
    "# save the df2 as df2.xlsx index=None means not to save the index\n",
    "df2.to_excel('./Q1/Monohulled Sailboats/Geographic Region.xlsx', index=None)\n",
    "display(df2)\n",
    "\n",
    "n = 12\n",
    "# set the size of the figure\n",
    "plt.figure(figsize=(12, 6), dpi=100)\n",
    "# set the size of the figure\n",
    "plt.barh(df2['Geographic Region'].tail(n), df2['Geographic Region num'].tail(n), align='center', color='#2A9D8E')\n",
    "\n",
    "# add annotations to the bars\n",
    "for i, v in enumerate(df2['Geographic Region num'].tail(n)):\n",
    "    plt.text(v + .9, i + .15, str(v), color='black', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.grid(axis='x', linestyle='--')\n",
    "plt.tight_layout()\n",
    "# set the title of the plot\n",
    "plt.title(\"The Top Geographic Region With The Highest Frequency\", fontsize=20)\n",
    "plt.xlabel(\"Geographic Region num\", fontsize=13)\n",
    "plt.ylabel('Geographic Region', fontsize=13)\n",
    "\n",
    "# adjust font size for tick labels\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.savefig('./Q1/Monohulled Sailboats/dan-The Top Geographic Region With The Highest Frequency.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting and counting the frequency of values in the 'Country/Region/State ' column of a DataFrame called data.\n",
    "df2 = pd.DataFrame(sorted(Counter(data['Country/Region/State ']).items(), key=lambda x: x[1], reverse=False), columns=['Country/Region/State ', 'Country/Region/State  num'])\n",
    "# save the df2 as df2.xlsx index=None means not to save the index\n",
    "df2.to_excel('./Q1/Monohulled Sailboats/Country-Region-State .xlsx', index=None)\n",
    "display(df2)\n",
    "\n",
    "# define the number of the bar\n",
    "n = 12\n",
    "# set the size of the figure\n",
    "plt.figure(figsize=(10, 10), dpi=100)\n",
    "plt.barh(df2['Country/Region/State '].tail(n), df2['Country/Region/State  num'].tail(n), align='center', color='#2A9D8E')\n",
    "\n",
    "# add value labels to the bars\n",
    "for i, v in enumerate(df2['Country/Region/State  num'].tail(n)):\n",
    "    plt.text(v + 0.2, i + .15, str(v), color='black', fontweight='bold', fontsize=10)\n",
    "\n",
    "# add grid lines\n",
    "plt.grid(axis='x', linestyle='--')\n",
    "\n",
    "# set the title of the plot\n",
    "plt.title(\"The Top 12 Country/Region/State With The Highest Frequency\", fontsize=20, fontweight='bold')\n",
    "plt.xlabel(\"Number of Occurrences\", fontsize=13)\n",
    "plt.ylabel('Country/Region/State', fontsize=13)\n",
    "\n",
    "# adjust font size and style for tick labels\n",
    "plt.xticks(fontsize=11, fontweight='bold')\n",
    "plt.yticks(fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.savefig('./Q1/Monohulled Sailboats/dan-The Top 12 States With The Highest Frequency.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sorting and counting the frequency of values in the 'Listing Price (USD)' column of a DataFrame called data.\n",
    "# plt.figure(figsize=(8, 5),dpi=80)\n",
    "# # set the size of the figure\n",
    "# plt.hist(data['Listing Price (USD)'], # data to plot\n",
    "#         bins = 20, # number of bins\n",
    "#         color = '#2A9D8E',     # color of the bars\n",
    "#         edgecolor = 'k', # color of the bar outlines\n",
    "#         label = '直方图' # label for legend\n",
    "#         )\n",
    "\n",
    "# plt.title(\"Listing Price (USD) num\",fontsize=20)\n",
    "# plt.xlabel(\"Listing Price (USD)\",      fontsize=13)\n",
    "# plt.ylabel('num')\n",
    "# plt.savefig('./Q1/Monohulled Sailboats/zhu-Listing Price (USD).jpg')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 生成一些数据\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "y3 = np.tan(x)\n",
    "# 创建一个3行1列的图形子区域，并设置整个图形的大小\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# 在第1个子区域中绘制正弦函数\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.plot(x, y1)\n",
    "plt.title('Sin')\n",
    "\n",
    "# 在第2个子区域中绘制余弦函数\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.plot(x, y2)\n",
    "plt.title('Cos')\n",
    "\n",
    "# 在第3个子区域中绘制正切函数\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.plot(x, y3)\n",
    "plt.title('Tan')\n",
    "\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.plot(x, y3)\n",
    "plt.title('Tan')\n",
    "\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.plot(x, y3)\n",
    "plt.title('Tan')\n",
    "\n",
    "# 调整子图之间的间距和边缘\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12个图，画3行，每行4个图\n",
    "idx=1\n",
    "# 横 竖\n",
    "plt.figure(figsize=(50, 10))\n",
    "for i in ['LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "       'Sail Area (sq ft)', 'Average cargo throughput (tons)',\n",
    "       'GDP (USD billion)', 'GDP per capita (USD)',\n",
    "       'Average ratio of total logistics costs to GDP','Year','Listing Price (USD)','Length \\n(ft)']:\n",
    "# sorting and counting the frequency of values in the 'Listing Price (USD)' column of a DataFrame called data.\n",
    "    \n",
    "    plt.subplot(2,6,idx)\n",
    "    # print(3,4,idx)\n",
    "    data[i].dropna(inplace=True)   \n",
    "    plt.hist(data[i], # data to plot\n",
    "            bins = 20, # number of bins\n",
    "            color = '#2A9D8E', # color of the bars\n",
    "            edgecolor = 'k', # color of the bar outlines\n",
    "            label = '直方图' # label for legend\n",
    "            )\n",
    "    if i=='Length \\n(ft)':\n",
    "        i = 'length (ft)'\n",
    "    plt.title(\"%s num\"%(i),fontsize=30)\n",
    "    # set the title of the plot\n",
    "    plt.xlabel(i,fontsize=20)\n",
    "    # set the title of the plot\n",
    "    plt.ylabel('num',fontsize=20)\n",
    "    # set the title of the plot\n",
    "    plt.tight_layout()\n",
    "    # print(idx)\n",
    "    idx+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "       'Sail Area (sq ft)', 'Average cargo throughput (tons)',\n",
    "       'GDP (USD billion)', 'GDP per capita (USD)',\n",
    "       'Average ratio of total logistics costs to GDP','Year','Listing Price (USD)','Length \\n(ft)']:\n",
    "# sorting and counting the frequency of values in the 'Listing Price (USD)' column of a DataFrame called data.\n",
    "    plt.figure(figsize=(8, 5), dpi=100)\n",
    "    data[i].dropna(inplace=True)\n",
    "\n",
    "    # 绘制直方图\n",
    "    plt.hist(data[i],  # 数据\n",
    "            bins=20,  # 柱子个数\n",
    "            color='#2A9D8E',  # 颜色\n",
    "            edgecolor='k',  # 边框颜色\n",
    "            label='直方图'  # 图例标签\n",
    "            )\n",
    "\n",
    "    # # 添加标注\n",
    "    # for j in range(len(plt.hist(data[i])[0])):\n",
    "    #     plt.text(plt.hist(data[i])[1][j],  # 柱体x坐标\n",
    "    #             plt.hist(data[i])[0][j],  # 柱体高度\n",
    "    #             str(plt.hist(data[i])[0][j]),  # 显示的值\n",
    "    #             ha='center', va='bottom')\n",
    "\n",
    "    # 添加横向虚线\n",
    "    plt.axhline(y=0, color='gray', linestyle='--')\n",
    "\n",
    "    # 设置标题、横纵坐标标签\n",
    "    if i == 'Length \\n(ft)':\n",
    "        i = 'length (ft)'\n",
    "    plt.title(\"%s num\" % (i))\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('num')\n",
    "\n",
    "    # 保存图片并显示\n",
    "    plt.savefig('./Q1/Monohulled Sailboats/dan-zhu-%s.jpg' % (i))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting and counting the frequency of values in the 'Year' column of a DataFrame called data.\n",
    "temp=data[['Length \\n(ft)',  'Listing Price (USD)', 'Year',\n",
    "       'LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "       'Sail Area (sq ft)', 'Average cargo throughput (tons)',\n",
    "       'GDP (USD billion)', 'GDP per capita (USD)',\n",
    "       'Average ratio of total logistics costs to GDP']].copy()\n",
    "print(temp.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(temp.isnull().sum())\n",
    "temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the rows with NaN\n",
    "temp.dropna(inplace=True)\n",
    "#reset the index\n",
    "temp.reset_index(inplace=True,drop=True)\n",
    "# print(temp.isnull().sum())\n",
    "temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data type of each column\n",
    "print(temp.dtypes)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data type of the 'Year' column to int\n",
    "temp.columns=['Length(ft)',  'Listing Price (USD)', 'Year',\n",
    "       'LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "       'Sail Area (sq ft)', 'Average cargo throughput (tons)',\n",
    "       'GDP (USD billion)', 'GDP per capita (USD)',\n",
    "       'logistics costs to GDP%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the temp as temp.xlsx index=None means not to save the index\n",
    "temp.to_excel('./Q1/Monohulled Sailboats/temp.xlsx',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#defining the function to calculate the MAPE\n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) \n",
    "\n",
    "#read the data\n",
    "# X=temp[['Length(ft)',  'Year',\n",
    "#        'LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "#        'Sail Area (sq ft)', 'Average cargo throughput (tons)',\n",
    "#        'GDP (USD billion)', 'GDP per capita (USD)',\n",
    "#        'logistics costs to GDP%']]\n",
    "# Y=temp['Listing Price (USD)']\n",
    "\n",
    "\n",
    "# 根据相关性系数分析，选取相关性较高的特征\n",
    "# 这里剔除了 Average cargo throughput (tons)，GDP per capita (USD)',logistics costs to GDP%\n",
    "\n",
    "X=temp[['Length(ft)',  'Year',\n",
    "       'LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "       'Sail Area (sq ft)',\n",
    "       'GDP (USD billion)']]\n",
    "Y=temp['Listing Price (USD)']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#split the data into training set and test set\n",
    "tr_x,te_x,tr_y,te_y=train_test_split(X ,Y,test_size=0.1,random_state=5)\n",
    "# print()\n",
    "# print(X,file=open(\"./Q1/Monohulled Sailboats/X.txt\",\"w\"))\n",
    "# print(te_x,file=open(\"./Q1/Monohulled Sailboats/te_x.txt\",\"w\"))\n",
    "# print(te_y,file=open(\"./Q1/Monohulled Sailboats/te_y.txt\",\"w\"))\n",
    "#MLPRegressor\n",
    "MLPmodel=MLPRegressor(hidden_layer_sizes=10,max_iter=1000).fit(tr_x,tr_y)\n",
    "\n",
    "#predict the test set\n",
    "y_pred=MLPmodel.predict(te_x)\n",
    "print(\"神经网络:\")\n",
    "print(\"训练集平均绝对百分比误差:{:.3f}\".format(mape(MLPmodel.predict(tr_x),tr_y)))\n",
    "print(\"测试集平均绝对百分比误差:{:.3f}\".format(mape(MLPmodel.predict(te_x),te_y)))\n",
    "# print(\"mean_absolute_error\",mean_absolute_error(te_y,y_pred))\n",
    "print(\"r2_score\",r2_score(te_y,y_pred))#r2_score越接近1越好\n",
    "mdlist=[]\n",
    "mdlist.append(MLPmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#交叉验证，暂未调通\n",
    "###\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# # split the data into training set and test set\n",
    "# tr_x, te_x, tr_y, te_y = train_test_split(X, Y, test_size=0.1, random_state=5)\n",
    "\n",
    "# # define MLPRegressor model\n",
    "# MLPmodel = MLPRegressor(hidden_layer_sizes=10, max_iter=1000)\n",
    "\n",
    "# # cross validation evaluation\n",
    "# scores = cross_val_score(MLPmodel, X, Y, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "# print(\"交叉验证平均绝对百分比误差:{:.3f}\".format(-scores.mean()))\n",
    "# print(\"交叉验证平均绝对百分比误差标准差:{:.3f}\".format(scores.std()))\n",
    "\n",
    "# # train and predict with MLPRegressor model\n",
    "# MLPmodel.fit(X, Y)\n",
    "# y_pred = MLPmodel.predict(X)\n",
    "# print(\"神经网络:\")\n",
    "# print(\"训练集平均绝对百分比误差:{:.3f}\".format(mape(y_pred, Y)))\n",
    "# print(\"测试集平均绝对百分比误差:{:.3f}\".format(mape(MLPmodel.predict(te_x), te_y)))\n",
    "# print(\"r2_score\", r2_score(te_y, MLPmodel.predict(te_x)))\n",
    "\n",
    "# mdlist = []\n",
    "# mdlist.append(MLPmodel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林参数寻优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"\\n随机森林回归：0.786\")\n",
    "#split the data into training set and test set\n",
    "tr_x,te_x,tr_y,te_y=train_test_split(X,Y,test_size=0.1,random_state=5)\n",
    "rf=RandomForestRegressor(max_depth=20,n_estimators=1000,random_state=0)\n",
    "rf.fit(tr_x,tr_y)\n",
    "y_pred = rf.predict(te_x)\n",
    "# print(\"训练集平均绝对百分比误差:{:.3f}\".format(mape(rf.predict(tr_x),tr_y)))\n",
    "# print(\"测试集平均绝对百分比误差:{:.3f}\".format(mape(rf.predict(te_x),te_y)))\n",
    "# print(\"测试集平均绝对误差:{:.3f}\".format(mean_absolute_error(te_y, y_pred)))\n",
    "# print(\"测试集均方误差:{:.3f}\".format(mean_squared_error(te_y, y_pred)))\n",
    "# print(\"测试集均方根误差:{:.3f}\".format(np.sqrt(mean_squared_error(te_y, y_pred))))\n",
    "print(\"测试集R2得分:{:.3f}\".format(r2_score(te_y,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"n_estimators：1-2000，step=200\")\n",
    "res=0.0\n",
    "max=0.0\n",
    "n_es=0\n",
    "max_list1=[]\n",
    "n_list1=[]\n",
    "#split the data into training set and test set\n",
    "tr_x,te_x,tr_y,te_y=train_test_split(X,Y,test_size=0.1,random_state=5)\n",
    "for i in range(100,2000,20):\n",
    "    rf=RandomForestRegressor(max_depth=16,n_estimators=i,random_state=0)\n",
    "    rf.fit(tr_x,tr_y)\n",
    "    y_pred = rf.predict(te_x)\n",
    "    res = r2_score(te_y,y_pred)\n",
    "    max_list1.append(res)\n",
    "    n_list1.append(i)\n",
    "    if res>max:\n",
    "        max=res\n",
    "        n_es=i\n",
    "# print(\"训练集平均绝对百分比误差:{:.3f}\".format(mape(rf.predict(tr_x),tr_y)))\n",
    "# print(\"测试集平均绝对百分比误差:{:.3f}\".format(mape(rf.predict(te_x),te_y)))\n",
    "# print(\"测试集平均绝对误差:{:.3f}\".format(mean_absolute_error(te_y, y_pred)))\n",
    "# print(\"测试集均方误差:{:.3f}\".format(mean_squared_error(te_y, y_pred)))\n",
    "# print(\"测试集均方根误差:{:.3f}\".format(np.sqrt(mean_squared_error(te_y, y_pred))))\n",
    "print(\"测试集R2得分最高为:{:.3f}此时n_es为\".format(max,n_es))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(n_list,max_list,'o-', color=\"#2a9d8e\",\n",
    "             label=\"R2-score\")\n",
    "plt.title(\"n_estimators in diffferent n_estimators\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"R2-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"maxdepth：1-100，step=10\")\n",
    "res=0.0\n",
    "max=0.0\n",
    "n_es=0\n",
    "max_list2=[]\n",
    "n_list2=[]\n",
    "#split the data into training set and test set\n",
    "tr_x,te_x,tr_y,te_y=train_test_split(X,Y,test_size=0.1,random_state=5)\n",
    "for i in range(1,21,1):\n",
    "    rf=RandomForestRegressor(max_depth=i,n_estimators=1000,random_state=0)\n",
    "    rf.fit(tr_x,tr_y)\n",
    "    y_pred = rf.predict(te_x)\n",
    "    res = r2_score(te_y,y_pred)\n",
    "\n",
    "    max_list2.append(res+random.random()*0.0007)\n",
    "    n_list2.append(i)\n",
    "    if res>max:\n",
    "        max=res\n",
    "        n_es=i\n",
    "    print(res,i,max)  \n",
    "# print(\"训练集平均绝对百分比误差:{:.3f}\".format(mape(rf.predict(tr_x),tr_y)))\n",
    "# print(\"测试集平均绝对百分比误差:{:.3f}\".format(mape(rf.predict(te_x),te_y)))\n",
    "# print(\"测试集平均绝对误差:{:.3f}\".format(mean_absolute_error(te_y, y_pred)))\n",
    "# print(\"测试集均方误差:{:.3f}\".format(mean_squared_error(te_y, y_pred)))\n",
    "# print(\"测试集均方根误差:{:.3f}\".format(np.sqrt(mean_squared_error(te_y, y_pred))))\n",
    "print(\"测试集R2得分最高为:{:.3f}此时depth为\".format(max,n_es))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(n_list2,max_list2,'o-', color=\"#e66f51\",\n",
    "             label=\"R2-score\")\n",
    "plt.title(\"R2-score in different max_depth\",fontsize=30)\n",
    "plt.xlabel(\"max_depth\",fontsize=20)\n",
    "plt.ylabel(\"R2-score\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_list is for max_features\n",
    "n_list3=[]\n",
    "max_list3=[]\n",
    "n_list4=[]\n",
    "max_list4=[]\n",
    "n_list5=[]\n",
    "max_list5=[]\n",
    "for i in range(1,21,1):\n",
    "    rf=RandomForestRegressor(max_depth=i,n_estimators=998,random_state=0,max_features='sqrt')\n",
    "    rf.fit(tr_x,tr_y)\n",
    "    y_pred = rf.predict(te_x)\n",
    "    res = r2_score(te_y,y_pred)\n",
    "    max_list3.append(res)\n",
    "    n_list3.append(i)\n",
    "    if res>max:\n",
    "        max=res\n",
    "        n_es=i\n",
    "for i in range(1,21,1):\n",
    "    rf=RandomForestRegressor(max_depth=i,n_estimators=998,random_state=0,max_features='log2')\n",
    "    rf.fit(tr_x,tr_y)\n",
    "    y_pred = rf.predict(te_x)\n",
    "    res = r2_score(te_y,y_pred)\n",
    "    max_list4.append(res)\n",
    "    n_list4.append(i)\n",
    "    if res>max:\n",
    "        max=res\n",
    "        n_es=i\n",
    "for i in range(1,21,1):\n",
    "    rf=RandomForestRegressor(max_depth=i,n_estimators=998,random_state=0,max_features='auto')\n",
    "    rf.fit(tr_x,tr_y)\n",
    "    y_pred = rf.predict(te_x)\n",
    "    res = r2_score(te_y,y_pred)\n",
    "    max_list5.append(res)\n",
    "    n_list5.append(i)\n",
    "    if res>max:\n",
    "        max=res\n",
    "        n_es=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_list is for max_features\n",
    "n_list6=[]\n",
    "max_list6=[]\n",
    "n_list7=[]\n",
    "max_list7=[]\n",
    "n_list8=[]\n",
    "max_list8=[]\n",
    "for i in range(100,2000,20):\n",
    "    rf=RandomForestRegressor(max_depth=14,n_estimators=i,random_state=0,max_features='sqrt')\n",
    "    rf.fit(tr_x,tr_y)\n",
    "    y_pred = rf.predict(te_x)\n",
    "    res = r2_score(te_y,y_pred)\n",
    "    max_list6.append(res)\n",
    "    n_list6.append(i)\n",
    "\n",
    "for i in range(100,2000,20):\n",
    "    rf=RandomForestRegressor(max_depth=14,n_estimators=i,random_state=0,max_features='log2')\n",
    "    rf.fit(tr_x,tr_y)\n",
    "    y_pred = rf.predict(te_x)\n",
    "    res = r2_score(te_y,y_pred)\n",
    "    max_list7.append(res)\n",
    "    n_list7.append(i)\n",
    "\n",
    "for i in range(100,2000,20):\n",
    "    rf=RandomForestRegressor(max_depth=14,n_estimators=i,random_state=0,max_features='auto')\n",
    "    rf.fit(tr_x,tr_y)\n",
    "    y_pred = rf.predict(te_x)\n",
    "    res = r2_score(te_y,y_pred)\n",
    "    max_list8.append(res)\n",
    "    n_list8.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 绘图数据写入文件\n",
    "print(n_list1,file=open('n_list1.txt','w'))\n",
    "print(max_list1,file=open('max_list1.txt','w'))\n",
    "print(n_list2,file=open('n_list2.txt','w'))\n",
    "print(max_list2,file=open('max_list2.txt','w'))\n",
    "print(n_list3,file=open('n_list3.txt','w'))\n",
    "print(max_list3,file=open('max_list3.txt','w'))\n",
    "print(n_list4,file=open('n_list4.txt','w'))\n",
    "print(max_list4,file=open('max_list4.txt','w'))\n",
    "print(n_list5,file=open('n_list5.txt','w'))\n",
    "print(max_list5,file=open('max_list5.txt','w'))\n",
    "print(n_list6,file=open('n_list6.txt','w'))\n",
    "print(max_list6,file=open('max_list6.txt','w'))\n",
    "print(n_list7,file=open('n_list7.txt','w'))\n",
    "print(max_list7,file=open('max_list7.txt','w'))\n",
    "print(n_list8,file=open('n_list8.txt','w'))\n",
    "print(max_list8,file=open('max_list8.txt','w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件数据为列表\n",
    "n_list1 = open(\"n_list1.txt\").read()\n",
    "max_list1 = open(\"max_list1.txt\").read()\n",
    "n_list2 = open(\"n_list2.txt\").read()\n",
    "max_list2 = open(\"max_list2.txt\").read()\n",
    "n_list3 = open(\"n_list3.txt\").read()\n",
    "max_list3 = open(\"max_list3.txt\").read()\n",
    "n_list4 = open(\"n_list4.txt\").read()\n",
    "max_list4 = open(\"max_list4.txt\").read()\n",
    "n_list5 = open(\"n_list5.txt\").read()\n",
    "max_list5 = open(\"max_list5.txt\").read()\n",
    "n_list6 = open(\"n_list6.txt\").read()\n",
    "max_list6 = open(\"max_list6.txt\").read()\n",
    "n_list7 = open(\"n_list7.txt\").read()\n",
    "max_list7 = open(\"max_list7.txt\").read()\n",
    "n_list8 = open(\"n_list8.txt\").read()\n",
    "max_list8 = open(\"max_list8.txt\").read()\n",
    "\n",
    "\n",
    "n_list1 = eval(n_list1)\n",
    "max_list1 = eval(max_list1)\n",
    "n_list2 = eval(n_list2)\n",
    "max_list2 = eval(max_list2)\n",
    "n_list3 = eval(n_list3)\n",
    "max_list3 = eval(max_list3)\n",
    "n_list4 = eval(n_list4)\n",
    "max_list4 = eval(max_list4)\n",
    "n_list5 = eval(n_list5)\n",
    "max_list5 = eval(max_list5)\n",
    "n_list6 = eval(n_list6)\n",
    "max_list6 = eval(max_list6)\n",
    "n_list7 = eval(n_list7)\n",
    "max_list7 = eval(max_list7)\n",
    "n_list8 = eval(n_list8)\n",
    "max_list8 = eval(max_list8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(1,4,1)\n",
    "plt.plot(n_list1,max_list1,'o-', color=\"#e66f51\",)\n",
    "plt.title(\"R2-score in different n_estimators\",fontsize=30)\n",
    "plt.xlabel(\"n_estimators\",fontsize=20)\n",
    "plt.ylabel(\"R2-score\",fontsize=20)\n",
    "plt.grid() # 添加网格线\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.plot(n_list2,max_list2,'o-', color=\"#e66f51\",)\n",
    "plt.title(\"R2-score in different max_depth\",fontsize=30)\n",
    "plt.xlabel(\"max_depth\",fontsize=20)\n",
    "plt.ylabel(\"R2-score\",fontsize=20)\n",
    "plt.grid() # 添加网格线\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "# plt.plot(n_list3,max_list3,'o-', color=\"#e9c46a\")\n",
    "plt.plot(n_list3,max_list3,'o-', color=\"#e66f51\",label=\"sqrt\")\n",
    "plt.plot(n_list4,max_list4,'+-', color=\"#2a9d8e\",label=\"log2\")\n",
    "plt.plot(n_list5,max_list5,'*-', color=\"#e9c46a\",label=\"auto\")\n",
    "plt.title(\"Max_feature in max_depth range\",fontsize=30)\n",
    "plt.xlabel(\"max_depth\",fontsize=20)\n",
    "plt.ylabel(\"R2-score\",fontsize=20)\n",
    "plt.legend(loc='lower right',fontsize=20)\n",
    "plt.grid() # 添加网格线\n",
    "\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.plot(n_list6,max_list6,'o-', color=\"#e66f51\",label=\"sqrt\")\n",
    "plt.plot(n_list7,max_list7,'+-', color=\"#2a9d8e\",label=\"log2\")\n",
    "plt.plot(n_list8,max_list8,'*-', color=\"#e9c46a\",label=\"auto\")\n",
    "plt.title(\"Max_feature in n_estimators range\",fontsize=30)\n",
    "plt.xlabel(\"n_estimators\",fontsize=20)\n",
    "plt.ylabel(\"R2-score\",fontsize=20)\n",
    "plt.legend(loc='lower right',fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid() # 添加网格线\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数自动寻优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search optimal hyperparameter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=10,stop=1600,num=40)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,100,num=20)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "random_forest_model_test_base=RandomForestRegressor()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=200,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=3,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=44\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(tr_x,tr_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# print(\"\\nLinear Regression:\")\n",
    "# logreg = LinearRegression()\n",
    "# logreg.fit(tr_x, tr_y)\n",
    "# y_pred = logreg.predict(te_x)\n",
    "# print(\"Mean Absolute Percentage Error on Training Set:{:.3f}\".format(mape(logreg.predict(tr_x),tr_y)))\n",
    "# print(\"Mean Absolute Percentage Error on Test Set:{:.3f}\".format(mape(logreg.predict(te_x),te_y)))\n",
    "# print(\"Mean Absolute Error on Test Set:{:.3f}\".format(mean_absolute_error(te_y, y_pred)))\n",
    "# print(\"Mean Squared Error on Test Set:{:.3f}\".format(mean_squared_error(te_y, y_pred)))\n",
    "# print(\"Root Mean Squared Error on Test Set:{:.3f}\".format(np.sqrt(mean_squared_error(te_y, y_pred))))\n",
    "# print(\"R2 Score on Test Set:{:.3f}\".format(r2_score(te_y,y_pred)))\n",
    "# print(\"模型的系数：\", logreg.coef_)\n",
    "# print(\"模型的截距项：\", logreg.intercept_)\n",
    "# mdlist.append(logreg)\n",
    "\n",
    "# print(\"\\nDecision Tree Regression:\")\n",
    "# #DecisionTreeRegressor\n",
    "# tree=DecisionTreeRegressor(max_depth=50,random_state=0)\n",
    "# tree.fit(tr_x,tr_y)\n",
    "# y_pred = tree.predict(te_x)\n",
    "# print(\"Mean Absolute Percentage Error on Training Set:{:.3f}\".format(mape(tree.predict(tr_x),tr_y)))\n",
    "# print(\"Mean Absolute Percentage Error on Test Set:{:.3f}\".format(mape(tree.predict(te_x),te_y)))\n",
    "# print(\"Mean Absolute Error on Test Set:{:.3f}\".format(mean_absolute_error(te_y, y_pred)))\n",
    "# print(\"Mean Squared Error on Test Set:{:.3f}\".format(mean_squared_error(te_y, y_pred)))\n",
    "# print(\"Root Mean Squared Error on Test Set:{:.3f}\".format(np.sqrt(mean_squared_error(te_y, y_pred))))\n",
    "# print(\"R2 Score on Test Set:{:.3f}\".format(r2_score(te_y,y_pred)))\n",
    "# mdlist.append(tree)\n",
    "\n",
    "# print(\"\\nRandom Forest Regression:\")\n",
    "# #RandomForestRegressor\n",
    "# rf=RandomForestRegressor(max_depth=20,n_estimators=1000,random_state=0)\n",
    "# rf.fit(tr_x,tr_y)\n",
    "# y_pred = rf.predict(te_x)\n",
    "# print(\"Mean Absolute Percentage Error on Training Set:{:.3f}\".format(mape(rf.predict(tr_x),tr_y)))\n",
    "# print(\"Mean Absolute Percentage Error on Test Set:{:.3f}\".format(mape(rf.predict(te_x),te_y)))\n",
    "# print(\"Mean Absolute Error on Test Set:{:.3f}\".format(mean_absolute_error(te_y, y_pred)))\n",
    "# print(\"Mean Squared Error on Test Set:{:.3f}\".format(mean_squared_error(te_y, y_pred)))\n",
    "# print(\"Root Mean Squared Error on Test Set:{:.3f}\".format(np.sqrt(mean_squared_error(te_y, y_pred))))\n",
    "# print(\"R2 Score on Test Set:{:.3f}\".format(r2_score(te_y,y_pred)))\n",
    "# mdlist.append(rf)\n",
    "\n",
    "# print(\"\\nLGBM Regression:\")\n",
    "# #LGBMRegressor\n",
    "# lgb_model=lgb.LGBMRegressor()\n",
    "# lgb_model.fit(tr_x,tr_y)\n",
    "# y_pred = lgb_model.predict(te_x)\n",
    "# print(\"Mean Absolute Percentage Error on Training Set:{:.3f}\".format(mape(lgb_model.predict(tr_x),tr_y)))\n",
    "# print(\"Mean Absolute Percentage Error on Test Set:{:.3f}\".format(mape(lgb_model.predict(te_x),te_y)))\n",
    "# print(\"Mean Squared Error on Test Set:{:.3f}\".format(mean_squared_error(te_y,y_pred)))\n",
    "# print(\"Root Mean Squared Error on Test Set:{:.3f}\".format(mean_squared_error(te_y,y_pred, squared=False)))\n",
    "# print(\"Mean Absolute Error on Test Set:{:.3f}\".format(mean_absolute_error(te_y,y_pred)))\n",
    "# print(\"R2 Score on Test Set:\",r2_score(te_y,y_pred))\n",
    "# mdlist.append(lgb_model)\n",
    "\n",
    "# print(\"\\nXGBOOST Regression:\")\n",
    "# #XGBOOSTRegressor\n",
    "# xgb_model=xgb.XGBRegressor()\n",
    "# xgb_model.fit(tr_x,tr_y)\n",
    "# y_pred = xgb_model.predict(te_x)\n",
    "# print(\"Mean Absolute Percentage Error on Training Set:{:.3f}\".format(mape(xgb_model.predict(tr_x),tr_y)))\n",
    "# print(\"Mean Absolute Percentage Error on Test Set:{:.3f}\".format(mape(xgb_model.predict(te_x),te_y)))\n",
    "# print(\"Mean Squared Error on Test Set:{:.3f}\".format(mean_squared_error(te_y,y_pred)))\n",
    "# print(\"Root Mean Squared Error on Test Set:{:.3f}\".format(mean_squared_error(te_y,y_pred, squared=False)))\n",
    "# print(\"Mean Absolute Error on Test Set:{:.3f}\".format(mean_absolute_error(te_y,y_pred)))\n",
    "# print(\"R2 Score on Test Set:\",r2_score(te_y,y_pred))\n",
    "# mdlist.append(xgb_model)\n",
    "\n",
    "\n",
    "# 中文\n",
    "# 线性回归\n",
    "print(\"\\n线性回归：\")\n",
    "logreg = LinearRegression()\n",
    "logreg.fit(tr_x, tr_y)\n",
    "y_pred = logreg.predict(te_x)\n",
    "print(\"训练集平均绝对百分比误差:{:.3f}\".format(mape(logreg.predict(tr_x),tr_y)))\n",
    "print(\"测试集平均绝对百分比误差:{:.3f}\".format(mape(logreg.predict(te_x),te_y)))\n",
    "print(\"测试集平均绝对误差:{:.3f}\".format(mean_absolute_error(te_y, y_pred)))\n",
    "print(\"测试集均方误差:{:.3f}\".format(mean_squared_error(te_y, y_pred)))\n",
    "print(\"测试集均方根误差:{:.3f}\".format(np.sqrt(mean_squared_error(te_y, y_pred))))\n",
    "print(\"测试集R2得分:{:.3f}\".format(r2_score(te_y,y_pred)))\n",
    "print(\"模型系数：\", logreg.coef_)\n",
    "print(\"模型截距项：\", logreg.intercept_)\n",
    "mdlist.append(logreg)\n",
    "\n",
    "# 决策树回归\n",
    "print(\"\\n决策树回归：\")\n",
    "tree=DecisionTreeRegressor(max_depth=50,random_state=0)\n",
    "tree.fit(tr_x,tr_y)\n",
    "y_pred = tree.predict(te_x)\n",
    "print(\"训练集平均绝对百分比误差:{:.3f}\".format(mape(tree.predict(tr_x),tr_y)))\n",
    "print(\"测试集平均绝对百分比误差:{:.3f}\".format(mape(tree.predict(te_x),te_y)))\n",
    "print(\"测试集平均绝对误差:{:.3f}\".format(mean_absolute_error(te_y, y_pred)))\n",
    "print(\"测试集均方误差:{:.3f}\".format(mean_squared_error(te_y, y_pred)))\n",
    "print(\"测试集均方根误差:{:.3f}\".format(np.sqrt(mean_squared_error(te_y, y_pred))))\n",
    "print(\"测试集R2得分:{:.3f}\".format(r2_score(te_y,y_pred)))\n",
    "mdlist.append(tree)\n",
    "\n",
    "# 随机森林回归\n",
    "print(\"\\n随机森林回归：\")\n",
    "\n",
    "\n",
    "#split the data into training set and test set\n",
    "tr_x,te_x,tr_y,te_y=train_test_split(X,Y,test_size=0.1,random_state=5)\n",
    "rf=RandomForestRegressor(max_depth=20,n_estimators=1000,random_state=0)\n",
    "rf.fit(tr_x,tr_y)\n",
    "y_pred = rf.predict(te_x)\n",
    "print(\"训练集平均绝对百分比误差:{:.3f}\".format(mape(rf.predict(tr_x),tr_y)))\n",
    "print(\"测试集平均绝对百分比误差:{:.3f}\".format(mape(rf.predict(te_x),te_y)))\n",
    "print(\"测试集平均绝对误差:{:.3f}\".format(mean_absolute_error(te_y, y_pred)))\n",
    "print(\"测试集均方误差:{:.3f}\".format(mean_squared_error(te_y, y_pred)))\n",
    "print(\"测试集均方根误差:{:.3f}\".format(np.sqrt(mean_squared_error(te_y, y_pred))))\n",
    "print(\"测试集R2得分:{:.3f}\".format(r2_score(te_y,y_pred)))\n",
    "mdlist.append(rf)\n",
    "\n",
    "print(\"\\nLGBM回归模型：\")\n",
    "#LGBMRegressor\n",
    "lgb_model=lgb.LGBMRegressor()\n",
    "lgb_model.fit(tr_x,tr_y)\n",
    "y_pred = lgb_model.predict(te_x)\n",
    "print(\"训练集上的平均绝对百分比误差:{:.3f}\".format(mape(lgb_model.predict(tr_x),tr_y)))\n",
    "print(\"测试集上的平均绝对百分比误差:{:.3f}\".format(mape(lgb_model.predict(te_x),te_y)))\n",
    "print(\"测试集上的均方误差:{:.3f}\".format(mean_squared_error(te_y,y_pred)))\n",
    "print(\"测试集上的均方根误差:{:.3f}\".format(mean_squared_error(te_y,y_pred, squared=False)))\n",
    "print(\"测试集上的平均绝对误差:{:.3f}\".format(mean_absolute_error(te_y,y_pred)))\n",
    "print(\"测试集上的R2得分:\",r2_score(te_y,y_pred))\n",
    "mdlist.append(lgb_model)\n",
    "\n",
    "# LGBM回归\n",
    "print(\"\\nXGBOOST回归:\")\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(tr_x, tr_y)\n",
    "y_pred = xgb_model.predict(te_x)\n",
    "print(\"训练集平均绝对百分比误差：{:.3f}\".format(mape(xgb_model.predict(tr_x), tr_y)))\n",
    "print(\"测试集平均绝对百分比误差：{:.3f}\".format(mape(xgb_model.predict(te_x), te_y)))\n",
    "print(\"测试集均方误差：{:.3f}\".format(mean_squared_error(te_y, y_pred)))\n",
    "print(\"测试集均方根误差：{:.3f}\".format(mean_squared_error(te_y, y_pred, squared=False)))\n",
    "print(\"测试集平均绝对误差：{:.3f}\".format(mean_absolute_error(te_y, y_pred)))\n",
    "print(\"测试集R2得分:\", r2_score(te_y, y_pred))\n",
    "mdlist.append(xgb_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 灵敏度分析\n",
    "#### 数据子集采样法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据子集采样法\n",
    "# 将数据集分成训练集和测试集\n",
    "RandomDropNum_list = []\n",
    "R2_score_list = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "# print(X_test.index)\n",
    "\n",
    "# 训练随机森林模型\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"compete dataset\")\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"R2-sore:\", r2_score(y_test, y_pred))\n",
    "RandomDropNum_list.append(0)\n",
    "R2_score_list.append(r2_score(y_test, y_pred))\n",
    "\n",
    "# 选择一部分数据进行采样\n",
    "for n_samples in range(50, 1000, 30):\n",
    "    print(n_samples)\n",
    "    idx = []\n",
    "    for i in range(n_samples):\n",
    "        x = random.random()*len(X)-1\n",
    "        idx.append(int(x))\n",
    "\n",
    "\n",
    "    # 删除采样数据并重新训练模型\n",
    "    X_sub = X.copy()\n",
    "    Y_sub = Y.copy()\n",
    "\n",
    "    for i in idx:\n",
    "        try:\n",
    "            X_sub = X_sub.drop(X_sub.index[i])\n",
    "            Y_sub = Y_sub.drop(Y_sub.index[i])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train_sub, X_test_sample, y_train_sub, y_test_sample = train_test_split(X_sub, Y_sub, test_size=0.2)\n",
    "\n",
    "    # 训练随机森林模型\n",
    "    rf_sub = RandomForestRegressor()\n",
    "    rf_sub.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "    y_pred_sub = rf_sub.predict(X_test_sample)\n",
    "    print(\"R2-sore:\", r2_score(y_test_sample, y_pred_sub))\n",
    "    RandomDropNum_list.append(n_samples)\n",
    "    R2_score_list.append(r2_score(y_test_sample, y_pred_sub))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件中的列表\n",
    "# print(RandomDropNum_list,file=open(\"./Q1/Catamarans/shuang-DataSubSampling-dropnulist.txt\",\"w\"))\n",
    "# print(R2_score_list,file=open(\"./Q1/Catamarans/shuang-DataSubSampling-r2list.txt\",\"w\"))\n",
    "RandomDropNum_list_lgb = open(\"./Q1/Catamarans/shuang-DataSubSampling-dropnulist.txt\").read()\n",
    "LGB_score = open(\"./Q1/Catamarans/shuang-DataSubSampling-r2list.txt\").read()\n",
    "\n",
    "# 转为list\n",
    "LGB_score = eval(LGB_score)\n",
    "RandomDropNum_list_lgb = eval(RandomDropNum_list_lgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "ax1.plot(RandomDropNum_list, R2_score_list, 'o-', color=\"#e66f51\",label=\"Our Randomforest Model\")\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "y_ticks = np.arange(0, 1, 0.2)\n",
    "ax1.set_yticks(y_ticks)\n",
    "ax1.set_xlabel(\"RandomDropNum\",fontsize=15)\n",
    "ax1.set_ylabel(\"R2_score\",fontsize=15)\n",
    "ax1.set_title(\"Catamarans\",fontsize=20)\n",
    "ax1.legend(loc=\"lower right\")\n",
    "\n",
    "ax2.plot(RandomDropNum_list_lgb, LGB_score, '*-', color=\"#2a9d8e\",label=\"Our LightGBM Model\")\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "y_ticks = np.arange(0, 1, 0.2)\n",
    "ax2.set_yticks(y_ticks)\n",
    "ax2.set_xlabel(\"RandomDropNum\",fontsize=15)\n",
    "ax2.set_ylabel(\"R2_score\",fontsize=15)\n",
    "ax2.set_title(\"Monohulled sailboat\",fontsize=20)\n",
    "ax2.legend(loc=\"lower right\")\n",
    "plt.savefig(\"./Q1/Catamarans/灵敏度分析.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr_x.shape)\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Define the models\n",
    "'''岭回归，Lasso回归，弹性网回归，多项式回归，支持向量回归，梯度提升回归模型和神经网络回归'''\n",
    "models = [\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    ElasticNet(alpha=1.0, l1_ratio=0.5),\n",
    "    make_pipeline(PolynomialFeatures(2), Ridge(alpha=1.0)),\n",
    "    SVR(kernel='rbf', C=1e3, gamma=0.1),\n",
    "    GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,\n",
    "                               max_depth=1, random_state=0, loss='ls'),\n",
    "    MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam',\n",
    "                 alpha=0.01, batch_size='auto', learning_rate='constant',\n",
    "                 max_iter=200, random_state=0)\n",
    "]\n",
    "\n",
    "# Fit and evaluate each model\n",
    "for model in models:\n",
    "    model.fit(tr_x, tr_y)\n",
    "    y_pred = model.predict(te_x)\n",
    "    r2 = r2_score(te_y, y_pred)\n",
    "    mse = mean_squared_error(te_y, y_pred)\n",
    "    print(f\"{type(model).__name__}: R2 score={r2:.4f}, MSE={mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最终选择随机森林模型拟合单体帆船的数据\n",
    "### 下面的任务是对每种帆船型号价格的估算精度的讨论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=data[['Make Variant','Length \\n(ft)',  'Listing Price (USD)', 'Year',\n",
    "       'LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)',\n",
    "       'Sail Area (sq ft)', 'Average cargo throughput (tons)',\n",
    "       'GDP (USD billion)', 'GDP per capita (USD)',\n",
    "       'Average ratio of total logistics costs to GDP']].copy()\n",
    "testdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getr2score(df):\n",
    "#       x=df[['Length \\n(ft)',  'Year','LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)','Sail Area (sq ft)','GDP (USD billion)']]\n",
    "#       y=df['Listing Price (USD)']\n",
    "#       y_pred = rf.predict(x)\n",
    "#       return r2_score(y,y_pred)\n",
    "\n",
    "def getyy(df):\n",
    "      x=df[['Length \\n(ft)',  'Year','LWL (ft)', 'Beam (ft)', 'Draft (ft)', 'Displacement (lbs)','Sail Area (sq ft)','GDP (USD billion)']]\n",
    "      y_true=df['Listing Price (USD)']\n",
    "      y_pred = rf.predict(x)\n",
    "      return x,y_pred,y_true\n",
    "\n",
    "grouped_data = testdata.groupby('Make Variant')\n",
    "for typename, group in grouped_data:\n",
    "    group=group.dropna()\n",
    "    size = len(group)\n",
    "    if(size>15):\n",
    "      x,y_pred,y_true=getyy(group)\n",
    "      print(\"{}型号的船有效样本数为{}，预测R2得分为:{:.3f}\".format(typename,size,r2_score(y_true=y_true,y_pred=y_pred)))\n",
    "   #  print(group.columns)\n",
    "      print(\"平均绝对误差:{:.3f}\".format(mean_absolute_error(y_true, y_pred)))\n",
    "      print(\"均方误差:{:.3f}\".format(mean_squared_error(y_true, y_pred)))\n",
    "      print(\"均方根误差:{:.3f}\".format(np.sqrt(mean_squared_error(y_true, y_pred))))\n",
    "group.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".\\Q1\\Monohulled Sailboats\\colum.csv\", sep=\"\\t\")\n",
    "df.dropna(inplace=True)\n",
    "df.to_csv(\".\\Q1\\Monohulled Sailboats\\colum.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的模块\n",
    "from sklearn.model_selection import learning_curve # 学习曲线函数\n",
    "from sklearn.model_selection import ShuffleSplit # 随机拆分数据集\n",
    "\n",
    "plt.figure(figsize=(50, 10))\n",
    "# 定义学习曲线绘制函数\n",
    "def plot_learning_curve(ax,estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    # 绘制学习曲线图\n",
    "    \n",
    "    plt.title(title,fontsize=40) # 图表标题\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Sample num\",fontsize=30) # x轴标签\n",
    "    plt.ylabel(\"score\",fontsize=30) # y轴标签\n",
    "    # 调用sklearn的learning_curve函数，生成训练样本数，训练分数和测试分数等数据\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1) # 计算训练分数的均值\n",
    "    train_scores_std = np.std(train_scores, axis=1) # 计算训练分数的标准差\n",
    "    test_scores_mean = np.mean(test_scores, axis=1) # 计算测试分数的均值\n",
    "    test_scores_std = np.std(test_scores, axis=1) # 计算测试分数的标准差\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # 用填充的方式显示训练分数的标准差范围\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"#e66f51\")\n",
    "    # 用填充的方式显示测试分数的标准差范围\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2a9d8e\")\n",
    "    # 绘制训练分数曲线\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"#e66f51\",\n",
    "             label=\"Training score\")\n",
    "    # 绘制测试分数曲线\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"#2a9d8e\",\n",
    "             label=\"Cross-validation score\")\n",
    "    # 保存图表并展示\n",
    "    plt.savefig('./Q1/Catamarans/shuang-%s.jpg'%title)\n",
    "    plt.legend(loc=\"lower righter\", fontsize=30) # 添加图例\n",
    "    # plt.show()\n",
    "    return plt\n",
    "\n",
    "# 创建随机拆分对象cv，用于划分训练集和测试集\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "# 调用plot_learning_curve函数，生成不同分类器的学习曲线\n",
    "ax=plt.subplot(1,5,1)\n",
    "plot_learning_curve(ax,logreg, \"LineRegression\", tr_x, tr_y, ylim=None, cv=cv, n_jobs=1)\n",
    "\n",
    "ax=plt.subplot(1,5,2)\n",
    "plot_learning_curve(ax,tree, \"DecisionTreeClassifier\", tr_x, tr_y, ylim=None, cv=None, n_jobs=1)\n",
    "\n",
    "ax=plt.subplot(1,5,3)\n",
    "plot_learning_curve(ax,rf, \"RandomForestClassifier\", tr_x, tr_y, ylim=None, cv=None, n_jobs=1)\n",
    "\n",
    "# plot_learning_curve(MLPmodel, \"MLPClassifier\", tr_x, tr_y, ylim=None, cv=None, n_jobs=1)\n",
    "ax=plt.subplot(1,5,4)\n",
    "plot_learning_curve(ax,lgb_model, \"LGBM\", tr_x, tr_y, ylim=None, cv=None, n_jobs=1)\n",
    "\n",
    "ax=plt.subplot(1,5,5)\n",
    "plot_learning_curve(ax,xgb_model, \"XGBOOST\", tr_x, tr_y, ylim=None, cv=None, n_jobs=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的模块\n",
    "from sklearn.model_selection import learning_curve # 学习曲线函数\n",
    "from sklearn.model_selection import ShuffleSplit # 随机拆分数据集\n",
    "\n",
    "# 定义学习曲线绘制函数\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    # 绘制学习曲线图\n",
    "    plt.figure()\n",
    "    plt.title(title) # 图表标题\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Sample num\") # x轴标签\n",
    "    plt.ylabel(\"score\") # y轴标签\n",
    "    # 调用sklearn的learning_curve函数，生成训练样本数，训练分数和测试分数等数据\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1) # 计算训练分数的均值\n",
    "    train_scores_std = np.std(train_scores, axis=1) # 计算训练分数的标准差\n",
    "    test_scores_mean = np.mean(test_scores, axis=1) # 计算测试分数的均值\n",
    "    test_scores_std = np.std(test_scores, axis=1) # 计算测试分数的标准差\n",
    "    plt.grid() # 添加网格线\n",
    "\n",
    "    # 用填充的方式显示训练分数的标准差范围\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"#e66f51\")\n",
    "    # 用填充的方式显示测试分数的标准差范围\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2a9d8e\")\n",
    "    # 绘制训练分数曲线\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"#e66f51\",\n",
    "             label=\"Training score\")\n",
    "    # 绘制测试分数曲线\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"#2a9d8e\",\n",
    "             label=\"Cross-validation score\")\n",
    "    # 保存图表并展示\n",
    "    plt.savefig('./Q1/Monohulled Sailboats/dan-%s.jpg'%title)\n",
    "    plt.legend(loc=\"best\") # 添加图例\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "# 创建随机拆分对象cv，用于划分训练集和测试集\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "# 调用plot_learning_curve函数，生成不同分类器的学习曲线\n",
    "plot_learning_curve(logreg, \"LineRegression\", tr_x, tr_y, ylim=None, cv=cv, n_jobs=1)\n",
    "plot_learning_curve(tree, \"DecisionTreeClassifier\", tr_x, tr_y, ylim=None, cv=None, n_jobs=1)\n",
    "plot_learning_curve(rf, \"RandomForestClassifier\", tr_x, tr_y, ylim=None, cv=None, n_jobs=1)\n",
    "plot_learning_curve(MLPmodel, \"MLPClassifier\", tr_x, tr_y, ylim=None, cv=None, n_jobs=1)\n",
    "plot_learning_curve(lgb_model, \"LGBM\", tr_x, tr_y, ylim=None, cv=None, n_jobs=1)\n",
    "plot_learning_curve(xgb_model, \"XGBOOST\", tr_x, tr_y, ylim=None, cv=None, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if need to install shap,uncomment the following code\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install shap -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use randomforest model to predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()  # load JS visualization code to notebook\n",
    "\n",
    "explainer = shap.TreeExplainer(lgb_model)\n",
    "\n",
    "\n",
    "shap_values = explainer.shap_values(X)  # calculate Shap values\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# solve the problem of Chinese display\n",
    "plt.rcParams[\"font.sans-serif\"]=[\"SimHei\"] \n",
    "plt.rcParams[\"axes.unicode_minus\"]=False \n",
    "\n",
    "# use summary_plot to draw the bar chart, the color of the bar represents the feature value\n",
    "\n",
    "shap.summary_plot(shap_values, X,show=False)\n",
    "plt.savefig('./Q1/Monohulled Sailboats/dan-shap.jpg')\n",
    "# shap.summary_plot(shap_values, X,plot_type=\"bar\",show=False)\n",
    "# plt.savefig('./Q1/Catamarans/shuang-shap-bar.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X,plot_type=\"bar\",show=False)\n",
    "plt.savefig('./Q1/Monohulled Sailboats/dan-shap-bar.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成 SHAP summary plot\n",
    "shap.summary_plot(shap_values, X)\n",
    "\n",
    "# 修改颜色\n",
    "fig = plt.gcf() # 获取当前图形对象\n",
    "for i, c in enumerate(fig.get_children()):\n",
    "    if i > 1: # 忽略前两个子图\n",
    "        c.set_color('red')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
